---
title: "Analysis of presidential inaugural speeches - based on Party"
output: html_notebook
---

# Introduction

### Inaugural speech is not only the the first official speech of any president of United States, but also reflects the personality, sentiment, interested topics for the next few years and so on. The following analysis mainly focus on the difference of inaugural speeches between Democratic Party and Republican Party(part 1). Then, we compare the inaugural speeches of DonaldJTrump and BarackObama(part 2).

```{r, message=FALSE, warning=FALSE, echo=FALSE}
# check and install needed packages. Load the libraries and functions. 

packages.used=c("rvest", "tibble", "qdap", 
                "sentimentr", "gplots", "dplyr",
                "tm", "syuzhet", "factoextra", 
                "beeswarm", "scales", "RColorBrewer",
                "RANN", "tm", "topicmodels")

# check packages that need to be installed.
packages.needed=setdiff(packages.used, 
                        intersect(installed.packages()[,1], 
                                  packages.used))
# install additional packages
if(length(packages.needed)>0){
  install.packages(packages.needed, dependencies = TRUE)
}

# load packages
library("rvest")
library("tibble")
# You may need to run
# sudo ln -f -s $(/usr/libexec/java_home)/jre/lib/server/libjvm.dylib /usr/local/lib
# in order to load qdap
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")

source("../lib/plotstacked.R")
source("../lib/speechFuncs.R")
```


```{r, echo=FALSE}
# construct the dataset

### Inauguaral speeches
main.page <- read_html(x = "http://www.presidency.ucsb.edu/inaugurals.php")
# Get link URLs
# f.speechlinks is a function for extracting links from the list of speeches. 
inaug=f.speechlinks(main.page)
as.Date(inaug[,1], format="%B %e, %Y")
inaug=inaug[-nrow(inaug),] # remove the last line, irrelevant due to error.

#### Nomination speeches
main.page=read_html("http://www.presidency.ucsb.edu/nomination.php")
# Get link URLs
nomin <- f.speechlinks(main.page)
#### Farewell speeches
main.page=read_html("http://www.presidency.ucsb.edu/farewell_addresses.php")
# Get link URLs
farewell <- f.speechlinks(main.page)

# prepared CSV data sets for the speeches we will scrap. 

inaug.list=read.csv("../data/inauglist.csv", stringsAsFactors = FALSE)
nomin.list=read.csv("../data/nominlist.csv", stringsAsFactors = FALSE)
farewell.list=read.csv("../data/farewelllist.csv", stringsAsFactors = FALSE)

# We assemble all scrapped speeches into one list. Note here that we don't have the full text yet, only the links to full text transcripts. 

# scrap the texts of speeches from the speech URLs.

nomin=nomin[-47, ]
speech.list=rbind(inaug.list, nomin.list, farewell.list)
speech.list$type=c(rep("inaug", nrow(inaug.list)),
                   rep("nomin", nrow(nomin.list)),
                   rep("farewell", nrow(farewell.list)))
speech.url=rbind(inaug, nomin, farewell)
speech.list=cbind(speech.list, speech.url)

# Loop over each row in speech.list
speech.list$fulltext=NA
for(i in seq(nrow(speech.list))) {
  text <- read_html(speech.list$urls[i]) %>% # load the page
    html_nodes(".displaytext") %>% # isloate the text
    html_text() # get the text
  speech.list$fulltext[i]=text
  # Create the file name
  filename <- paste0("../data/fulltext/", 
                     speech.list$type[i],
                     speech.list$File[i], "-", 
                     speech.list$Term[i], ".txt")
  sink(file = filename) %>% # open file to write 
  cat(text)  # write the file
  sink() # close the file
}

# combine the speeches of DonaldTrump
speech1=paste(readLines("../data/fulltext/SpeechDonaldTrump-NA.txt", 
                  n=-1, skipNul=TRUE),
              collapse=" ")
speech2=paste(readLines("../data/fulltext/SpeechDonaldTrump-NA2.txt", 
                  n=-1, skipNul=TRUE),
              collapse=" ")
speech3=paste(readLines("../data/fulltext/PressDonaldTrump-NA.txt", 
                  n=-1, skipNul=TRUE),
              collapse=" ")

Trump.speeches=data.frame(
  President=rep("Donald J. Trump", 3),
  File=rep("DonaldJTrump", 3),
  Term=rep(0, 3),
  Party=rep("Republican", 3),
  Date=c("August 31, 2016", "September 7, 2016", "January 11, 2017"),
  Words=c(word_count(speech1), word_count(speech2), word_count(speech3)),
  Win=rep("yes", 3),
  type=rep("speeches", 3),
  links=rep(NA, 3),
  urls=rep(NA, 3),
  fulltext=c(speech1, speech2, speech3)
)

speech.list=rbind(speech.list, Trump.speeches)

for (i in 1:nrow(speech.list)) {
  speech.list[i,6] = wc(speech.list[i,11])
}# count the words for each speech
```

```{r, echo=FALSE}
# look at the data we have
head(speech.list)
```

### Above is the dataset we constructed, which contains information related to inaugural speech like Party, number of words, date and so on.


# Part 1: The story of inaugural speeches of Democratic Party and Republican Party

### It is well known that Democrats and republicans have different platforms, development goals and different interests. So what are the similarities and differences of their speeches?

## 1.1 The change of number of words over time

```{r, echo=FALSE}
# look at the change of number of words over time
dem.speech.list=subset(speech.list, Party=='Democratic')
rep.speech.list=subset(speech.list, Party=='Republican')

# Democratic presidents
barplot(as.integer(dem.speech.list$Words), ylab = 'Words',col = "pink",
main = "Number of words of Democratic presidents' speeches")

# Republican presidents
barplot(as.integer(rep.speech.list$Words), ylab = 'Words',col = "light blue",
main = "Number of words of Republican presidents' speeches")
```

### According to the barplot above, we may see that:
### For Democratic presidents' speeches:
### (1) Most of the speeches are under 4000 words.
### (2) The number of words fluctuate over time.
### (3) As time goes by, there is a slight trend that their speeches contain more and more words.

### For Republican presidents' speeches:
### (1) Most of the speeches are under 5000 words.
### (2) The number of words fluctuate over time.
### (3) As time goes by, there is a slight trend that their speeches contain more and more words.

### It seems like that the word average number of Republican presidents' speeches is more than that of Democratic presidents' speeches. Is it right?

```{r, echo=FALSE}
# compare the average number of words from different Party
data = c(mean(as.integer(dem.speech.list$Words)), mean(as.integer(rep.speech.list$Words)))
name = c('Democratic', 'Republican')
barplot(data, names.arg = name, xlab = 'Party', ylab = 'Average Words',col = "grey",
main = "Average number of words of presidents' speeches")
```

### According to the graph above, we can see that the average word number of Democratic presidents' speeches is about 3000. As for Republican presidents' speeches, it is about 3500. So we have the right guess.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# generate list of sentences

sentence.list=NULL
for(i in 1:nrow(speech.list)){
  sentences=sent_detect(speech.list$fulltext[i],
                        endmarks = c("?", ".", "!", "|",";"))
  if(length(sentences)>0){
    emotions=get_nrc_sentiment(sentences)
    word.count=word_count(sentences)
    emotions=diag(1/(word.count+0.01))%*%as.matrix(emotions)
    sentence.list=rbind(sentence.list, 
                        cbind(speech.list[i,-ncol(speech.list)],
                              sentences=as.character(sentences), 
                              word.count,
                              emotions,
                              sent.id=1:length(sentences)
                              )
    )
  }
}

# Some non-sentences exist in raw data due to erroneous extra end-of-sentence marks. 
sentence.list=
  sentence.list%>%
  filter(!is.na(word.count)) 
```

## 1.2 Overview of sentence length distribution by different Party of speeches

### For simpler visualization, we chose a subset of better known presidents or presidential candidates on which to focus our analysis. 

```{r, echo=FALSE}
sel.comparison=c("DonaldJTrump","JohnMcCain", "GeorgeBush", "MittRomney", "GeorgeWBush",
                 "RonaldReagan","AlbertGore,Jr", "HillaryClinton","JohnFKerry", 
                 "WilliamJClinton","HarrySTruman", "BarackObama", "LyndonBJohnson",
                 "GeraldRFord", "JimmyCarter", "DwightDEisenhower", "FranklinDRoosevelt",
                 "HerbertHoover","JohnFKennedy","RichardNixon","WoodrowWilson", 
                 "AbrahamLincoln", "TheodoreRoosevelt", "JamesGarfield", 
                 "JohnQuincyAdams", "UlyssesSGrant", "ThomasJefferson",
                 "GeorgeWashington", "WilliamHowardTaft", "AndrewJackson",
                 "WilliamHenryHarrison", "JohnAdams")

print(sel.comparison)
```

### These are the presidnets we chose.

### For relevant to Trump's speeches, we will only compare speeches for the first terms of former U.S. presidents. 


## 1.2.1 Democratic

```{r, fig.width = 3, fig.height = 3, echo=FALSE}

par(mar=c(4, 11, 2, 2))

sentence.list.sel=filter(sentence.list, Party=='Democratic',
                        type=="inaug", Term==1, File%in%sel.comparison)
sentence.list.sel$File=factor(sentence.list.sel$File)

sentence.list.sel$FileOrdered=reorder(sentence.list.sel$File, 
                                  sentence.list.sel$word.count, 
                                  mean, 
                                  order=T)

beeswarm(word.count~FileOrdered, 
         data=sentence.list.sel,
         horizontal = TRUE, 
         pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), 
         cex=0.55, cex.axis=0.8, cex.lab=0.8,
         spacing=5/nlevels(sentence.list.sel$FileOrdered),
         las=2, xlab="Number of words in a sentence.", ylab="",
         main="Inaugural speeches")

```

### We may notice that most of their sentences are between 1 and 30 words. The distribution of number of words in a sentence is relatively smooth and average.


## 1.2.2 Republican

```{r, fig.width = 3, fig.height = 3, echo=FALSE}

par(mar=c(4, 11, 2, 2))
sentence.list.sel=filter(sentence.list, Party=='Republican',
                        type=="inaug", Term==1, File%in%sel.comparison)
sentence.list.sel$File=factor(sentence.list.sel$File)

sentence.list.sel$FileOrdered=reorder(sentence.list.sel$File, 
                                  sentence.list.sel$word.count, 
                                  mean, 
                                  order=T)

beeswarm(word.count~FileOrdered, 
         data=sentence.list.sel,
         horizontal = TRUE, 
         pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), 
         cex=0.55, cex.axis=0.8, cex.lab=0.8,
         spacing=5/nlevels(sentence.list.sel$FileOrdered),
         las=2, xlab="Number of words in a sentence.", ylab="",
         main="Inaugural speeches")

```
### As for Republican presidents, we find that they have more sentences under 20 words. So most of their points concentrate on the left side of the graph.


## 1.3 Clustering of emotions

```{r, fig.height=3.3, fig.width=3.7, echo=FALSE}
presid.summary=tbl_df(sentence.list)%>%
  filter(type=="inaug", File%in%sel.comparison)%>%
  group_by(File)%>%
  summarise(
    anger=mean(anger),
    anticipation=mean(anticipation),
    disgust=mean(disgust),
    fear=mean(fear),
    joy=mean(joy),
    sadness=mean(sadness),
    surprise=mean(surprise),
    trust=mean(trust),
    negative=mean(negative),
    positive=mean(positive)
  )

presid.summary=as.data.frame(presid.summary)
rownames(presid.summary)=as.character((presid.summary[,1]))
km.res=kmeans(presid.summary[,-1], iter.max=200,
              5)
fviz_cluster(km.res, 
             stand=F, repel= TRUE,
             data = presid.summary[,-1], xlab="", xaxt="n",
             show.clust.cent=FALSE)
```
### By clustering of emotions of all these chosen speeches from different Party, we can see that:
### (1) The speeches from different Party may be in the same emotion cluster, like William Howard Taft and BarackObama.
### (2) The speeches from the same Party may be in different emotion cluster, like Franklin D. Roosevelt and BarackObama.

### With all the finding we conclude from part 1, next we will focus on the difference of speeches between DonaldJTrump and BarackObama.


# Part 2: The story of inaugural speeches of DonaldJTrump and BarackObama

### Generally speaking, there are lots of differences between DonaldJTrump and BarackObama, ages, Parties, experience and so on. How about their inaugural speeches?

## 2.1 Overview of sentence length distribution

### For relevant to Trump's speeches, we will only compare speeches for the first terms of former U.S. presidents.

```{r, fig.width = 3, fig.height = 2, echo=FALSE}

sel.comparison2=c("DonaldJTrump", "BarackObama")

par(mar=c(4, 11, 2, 2))

sentence.list.sel=filter(sentence.list, 
                        type=="inaug", Term==1, File%in%sel.comparison2)
sentence.list.sel$File=factor(sentence.list.sel$File)

sentence.list.sel$FileOrdered=reorder(sentence.list.sel$File, 
                                  sentence.list.sel$word.count, 
                                  mean, 
                                  order=T)

beeswarm(word.count~FileOrdered, 
         data=sentence.list.sel,
         horizontal = TRUE, 
         pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6), 
         cex=0.55, cex.axis=0.8, cex.lab=0.8,
         spacing=5/nlevels(sentence.list.sel$FileOrdered),
         las=2, xlab="Number of words in a sentence.", ylab="",
         main="Inaugural speeches")

```

### It is obvious that DonaldJTrump has more short sentences than BarackObama. BarackObama has lots of sentences with more than 25 words.

### So will the number of words be different?

```{r, echo=FALSE}
# compare the average number of speech of Trump and Obama
word=c(mean(as.integer(speech.list[speech.list$President=='Donald J. Trump', ]$Words)), mean(as.integer(speech.list[speech.list$President=='Barack Obama', ]$Words)))
pre=c("DonaldJTrump", "BarackObama")
barplot(word, names.arg = pre, xlab = 'President', ylab = 'Average Words',col = "grey",
main = "Number of words of presidents' speeches")
```

### According to the barplot above, we can find that the speeches of DonaldJTrump has about 4300 words. However, the speeches of BarackObama has about 3600 words, which is much less than DonaldJTrump.


## 2.2 DonaldJTrump VS BarackObama, what are their short sentences?

```{r, echo=FALSE}
sentence.list%>%
  filter(File=="DonaldJTrump", 
         type=="inaug", 
         word.count<=3)%>%
  select(sentences)

sentence.list%>%
  filter(File=="BarackObama", 
         type=="inaug", 
         word.count<=3)%>%
  select(sentences)
```

### We will notice that most of their short sentences are similar, like 'Thank you'. The 'America first' in Trump's speech and the 'diversity and openness' in Obama's speech show a big difference in their concept of running a country, especially its external attitude.


## 2.3 Sentiment analsis

### The following analysis shows that sentence length variation over the course of the speech, with emotions. How the presidents alternate between long and short sentences and how they shift between different sentiments in their speeches. We use the same color to show the same emotion.

## 2.3.1 DonaldJTrump VS BarackObama

```{r, fig.height=2, fig.width=2, echo=FALSE}
par(mfrow=c(2,1), mar=c(1,0,2,0), bty="n", xaxt="n", yaxt="n", font.main=1)

f.plotsent.len(In.list=sentence.list, InFile="DonaldJTrump", 
               InType="inaug", InTerm=1, President="Donald Trump")

f.plotsent.len(In.list=sentence.list, InFile="BarackObama", 
               InType="inaug", InTerm=1, President="Barack Obama")

```

### It is obvious that the emotion of Trump's sentences are more easily changed. On contract, the emotion of Obama's sentences are more coherence.

### What are the emotionally charged sentences?

```{r, message=FALSE, warning=FALSE, echo=FALSE}
print("Donald Trump")
speech.df=tbl_df(sentence.list)%>%
  filter(File=="DonaldJTrump", type=="inaug", Term==1, word.count>=5)%>%
  select(sentences, anger:trust)
speech.df=as.data.frame(speech.df)
as.character(speech.df$sentences[apply(speech.df[,-1], 2, which.max)])

print("Barack Obama")
speech.df=tbl_df(sentence.list)%>%
  filter(File=="BarackObama", type=="inaug", Term==1, word.count>=5)%>%
  select(sentences, anger:trust)
speech.df=as.data.frame(speech.df)
as.character(speech.df$sentences[apply(speech.df[,-1], 2, which.max)])
```

### From the result above, we may find that the change of emotion is kind of related to the change of topics, like 'Today's ceremony, however, has very special meaning.' by Trump.


## 2.4 Topic modeling

### For topic modeling, we prepare a corpus of sentence snipets as follows. For each speech, we start with sentences and prepare a snipet with a given sentence with the flanking sentences. 

### Based on the most popular terms and the most salient terms for each topic, we assign a hashtag to each topic. These topics are "Economy", "America", "Defense", "Belief", "Election", "Patriotism", "Unity", "Government", "Reform", "Temporal", "WorkingFamilies", "Freedom", "Equality", "Misc" and "Legislation".

```{r, echo=FALSE}
corpus.list=sentence.list[2:(nrow(sentence.list)-1), ]
sentence.pre=sentence.list$sentences[1:(nrow(sentence.list)-2)]
sentence.post=sentence.list$sentences[3:(nrow(sentence.list)-1)]
corpus.list$snipets=paste(sentence.pre, corpus.list$sentences, sentence.post, sep=" ")
rm.rows=(1:nrow(corpus.list))[corpus.list$sent.id==1]
rm.rows=c(rm.rows, rm.rows-1)
corpus.list=corpus.list[-rm.rows, ]

# Text mining
docs <- Corpus(VectorSource(corpus.list$snipets))
writeLines(as.character(docs[[sample(1:nrow(corpus.list), 1)]]))

# Text basic processing, adapted from <https://eight2late.wordpress.com/2015/09/29/a-gentle-introduction-to-topic-modeling-using-r/>.
#remove potentially problematic symbols
docs <-tm_map(docs,content_transformer(tolower))
writeLines(as.character(docs[[sample(1:nrow(corpus.list), 1)]]))

#remove punctuation
docs <- tm_map(docs, removePunctuation)
writeLines(as.character(docs[[sample(1:nrow(corpus.list), 1)]]))

#Strip digits
docs <- tm_map(docs, removeNumbers)
writeLines(as.character(docs[[sample(1:nrow(corpus.list), 1)]]))

#remove stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
writeLines(as.character(docs[[sample(1:nrow(corpus.list), 1)]]))

#remove whitespace
docs <- tm_map(docs, stripWhitespace)
writeLines(as.character(docs[[sample(1:nrow(corpus.list), 1)]]))

#Stem document
docs <- tm_map(docs,stemDocument)
writeLines(as.character(docs[[sample(1:nrow(corpus.list), 1)]]))

#Gengerate document-term matrices. 
dtm <- DocumentTermMatrix(docs)
#convert rownames to filenames#convert rownames to filenames
rownames(dtm) <- paste(corpus.list$type, corpus.list$File,
                       corpus.list$Term, corpus.list$sent.id, sep="_")

rowTotals <- apply(dtm , 1, sum) #Find the sum of words in each Document

dtm  <- dtm[rowTotals> 0, ]
corpus.list=corpus.list[rowTotals>0, ]

#Run LDA
#Set parameters for Gibbs sampling
burnin <- 4000
iter <- 2000
thin <- 500
seed <-list(2003,5,63,100001,765)
nstart <- 5
best <- TRUE

#Number of topics
k <- 15

#Run LDA using Gibbs sampling
ldaOut <-LDA(dtm, k, method="Gibbs", control=list(nstart=nstart, 
                                                 seed = seed, best=best,
                                                 burnin = burnin, iter = iter, 
                                                 thin=thin))
#write out results
#docs to topics
ldaOut.topics <- as.matrix(topics(ldaOut))
table(c(1:k, ldaOut.topics))
write.csv(ldaOut.topics,file=paste("../output/LDAGibbs",k,"DocsToTopics.csv"))

#top 6 terms in each topic
ldaOut.terms <- as.matrix(terms(ldaOut,20))
write.csv(ldaOut.terms,file=paste("../output/LDAGibbs",k,"TopicsToTerms.csv"))

#probabilities associated with each topic assignment
topicProbabilities <- as.data.frame(ldaOut@gamma)
write.csv(topicProbabilities,file=paste("../output/LDAGibbs",k,"TopicProbabilities.csv"))

terms.beta=ldaOut@beta
terms.beta=scale(terms.beta)
topics.terms=NULL
for(i in 1:k){
  topics.terms=rbind(topics.terms, ldaOut@terms[order(terms.beta[i,], decreasing = TRUE)[1:7]])
}
topics.terms
ldaOut.terms

topics.hash=c("Economy", "America", "Defense", "Belief", "Election", "Patriotism", "Unity", "Government", "Reform", "Temporal", "WorkingFamilies", "Freedom", "Equality", "Misc", "Legislation")
corpus.list$ldatopic=as.vector(ldaOut.topics)
corpus.list$ldahash=topics.hash[ldaOut.topics]

colnames(topicProbabilities)=topics.hash
corpus.list.df=cbind(corpus.list, topicProbabilities)
```


## 2.4.1 Topics differences between Trump and Obama

```{r, fig.width=3.3, fig.height=3, echo=FALSE}
# [1] "Economy"         "America"         "Defense"         "Belief"         
# [5] "Election"        "Patriotism"      "Unity"           "Government"     
# [9] "Reform"          "Temporal"        "WorkingFamilies" "Freedom"        
# [13] "Equality"        "Misc"            "Legislation"       

par(mfrow=c(2, 1), mar=c(1,1,2,0), bty="n", xaxt="n", yaxt="n")

topic.plot=c(1:15)
print(topics.hash[topic.plot])
 
speech.df=tbl_df(corpus.list.df)%>%filter(File=="DonaldJTrump", type=="inaug")%>%select(sent.id, Economy:Legislation)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
            xlab="Sentences", ylab="Topic share", main="Donald Trump,  Inaugural Speeches")

speech.df=tbl_df(corpus.list.df)%>%filter(File=="BarackObama", type=="inaug", Term==1)%>%select(sent.id, Economy:Legislation)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
             xlab="Sentences", ylab="Topic share", main="Barack Obama, Inaugural Speeches")
```

### According to the result, we may find that:
### (1) For DonaldJTrump, a big part of his speech is related to legislation, equality, defense and America.
### (1) For BarackObama, it is equality, freedom, government and America.


## 2.4.2 How are the sentences related to topics?

```{r, echo=FALSE}
speech.df=tbl_df(corpus.list.df)%>%filter(type=="inaug", word.count<20)%>%select(sentences, Economy:Legislation)

as.character(speech.df$sentences[apply(as.data.frame(speech.df[,-1]), 2, which.max)])

names(speech.df)[-1]
```

### From the result above, we can clearly see how topic modeling work.


# Conclusion

### In conclusion, from these analysis, we may find a lot of differences between the inaugural speech of Democratic Party and Republican Party, including the number of words, sentence distribution, emotion cluster and so on.

### So as to DonaldJTrump from Republican Party and BarackObama from Democratic Party, they have lots of differences in their speech's pattern, like sentiment difference, topic difference and so on.

# Reference

### wk2-Tutorial-TextMining https://github.com/TZstatsADS/ADS_Teaching/tree/master/Tutorials/wk2-TextMining
